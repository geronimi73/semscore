{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98c177e-5049-4f42-b661-05b29bb6af29",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f787ea61-0e9b-4804-894b-978e86f6395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "-e git+https://github.com/geronimi73/accelerate@d25a787628e42ef9efcc165807ba7aa9fa9d56ae#egg=accelerate\n",
      "addict==2.4.0\n",
      "aenum==3.1.15\n",
      "aiodns==3.1.1\n",
      "aiofiles==23.1.0\n",
      "aiohttp==3.9.2\n",
      "aiohttp-retry==2.8.3\n",
      "aiosignal==1.3.1\n",
      "altair==5.1.1\n",
      "annotated-types==0.6.0\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.7.1\n",
      "apache-beam==2.52.0\n",
      "appdirs==1.4.4\n",
      "apturl==0.5.2\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "async-timeout==4.0.3\n",
      "attributedict==0.3.0\n",
      "attrs==23.1.0\n",
      "autoawq==0.1.8\n",
      "Babel==2.13.1\n",
      "backoff==2.2.1\n",
      "basicsr==1.4.2\n",
      "bcrypt==3.2.0\n",
      "beautifulsoup4==4.10.0\n",
      "beniget==0.4.1\n",
      "bitsandbytes==0.42.0\n",
      "black==23.12.1\n",
      "bleach==6.1.0\n",
      "blendmodes==2022\n",
      "blessings==1.7\n",
      "blinker==1.4\n",
      "boltons==23.0.0\n",
      "boto3==1.34.34\n",
      "botocore==1.34.34\n",
      "bottle==0.12.19\n",
      "Brlapi==0.8.3\n",
      "Brotli==1.1.0\n",
      "cached-property==1.5.2\n",
      "cachetools==5.3.2\n",
      "cattrs==23.2.3\n",
      "causal-conv1d==1.0.0\n",
      "certifi==2023.11.17\n",
      "cffi==1.16.0\n",
      "chardet==5.2.0\n",
      "charset-normalizer==3.2.0\n",
      "ci-info==0.3.0\n",
      "clean-fid==0.1.35\n",
      "click==8.1.7\n",
      "clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip\n",
      "cloudpickle==2.2.1\n",
      "cmake==3.27.4.1\n",
      "codecov==2.1.13\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "colour-runner==0.1.1\n",
      "comm==0.1.4\n",
      "command-not-found==0.3\n",
      "configobj==5.0.8\n",
      "configparser==6.0.0\n",
      "controlnet-aux==0.0.7\n",
      "coolgpus==0.23\n",
      "coverage==7.4.0\n",
      "crcmod==1.7\n",
      "cryptography==41.0.7\n",
      "cssselect2==0.7.0\n",
      "cuda-python==12.2.0\n",
      "cupshelpers==1.0\n",
      "cycler==0.11.0\n",
      "Cython==3.0.3\n",
      "dataclasses-json==0.6.3\n",
      "DataProperty==1.0.1\n",
      "datasets==2.16.1\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.8.0\n",
      "decorator==4.4.2\n",
      "deepdiff==6.7.1\n",
      "defer==1.0.6\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.14\n",
      "deprecation==2.1.0\n",
      "diffusers==0.23.1\n",
      "dill==0.3.7\n",
      "diskcache==5.6.3\n",
      "distlib==0.3.8\n",
      "distro==1.7.0\n",
      "distro-info==1.1+ubuntu0.1\n",
      "dnspython==2.4.2\n",
      "docker==5.0.3\n",
      "docker-pycreds==0.4.0\n",
      "docopt==0.6.2\n",
      "duplicity==0.8.21\n",
      "einops==0.7.0\n",
      "email-validator==2.1.0.post1\n",
      "etelemetry==0.3.1\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.3\n",
      "execnb==0.1.5\n",
      "executing==2.0.1\n",
      "facexlib==0.3.0\n",
      "fastapi==0.109.0\n",
      "fastavro==1.8.3\n",
      "fastcore==1.5.29\n",
      "fasteners==0.14.1\n",
      "fastjsonschema==2.18.1\n",
      "fastlangid==1.0.11\n",
      "fasttext==0.9.2\n",
      "ffmpy==0.3.1\n",
      "filelock==3.13.1\n",
      "filterpy==1.4.5\n",
      "fitz==0.0.1.dev2\n",
      "flash-attn==2.5.3\n",
      "flatbuffers==23.5.26\n",
      "fonttools==4.29.1\n",
      "fqdn==1.5.1\n",
      "frontend==0.0.3\n",
      "frozenlist==1.4.0\n",
      "fs==2.4.12\n",
      "fsspec==2023.6.0\n",
      "ftfy==6.1.3\n",
      "future==0.18.2\n",
      "fvcore==0.1.5.post20221221\n",
      "gast==0.5.2\n",
      "gdown==4.7.1\n",
      "gfpgan==1.3.8\n",
      "ghapi==1.0.4\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.32\n",
      "Glances==3.2.4.2\n",
      "google-auth==2.23.0\n",
      "google-auth-oauthlib==1.0.0\n",
      "gql==3.5.0\n",
      "gradio==3.41.2\n",
      "gradio_client==0.5.0\n",
      "graphql-core==3.2.3\n",
      "greenlet==3.0.3\n",
      "grpcio==1.58.0\n",
      "h11==0.12.0\n",
      "hdfs==2.7.2\n",
      "hf-doc-builder==0.4.0\n",
      "hjson==3.1.0\n",
      "html5lib==1.1\n",
      "httpcore==0.15.0\n",
      "httplib2==0.20.2\n",
      "httptools==0.6.1\n",
      "httpx==0.24.1\n",
      "huggingface-hub==0.19.4\n",
      "humanfriendly==10.0\n",
      "idna==3.3\n",
      "imageio==2.31.5\n",
      "img2pdf==0.5.1\n",
      "immutabledict==3.0.0\n",
      "importlib-metadata==6.8.0\n",
      "importlib-resources==6.1.0\n",
      "inflate64==1.0.0\n",
      "inflection==0.5.1\n",
      "influxdb==5.3.1\n",
      "inquirerpy==0.3.4\n",
      "inspecta==0.1.3\n",
      "iopath==0.1.9\n",
      "ipykernel==6.26.0\n",
      "ipyplot==1.1.1\n",
      "ipython==8.17.2\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "itsdangerous==2.1.2\n",
      "jedi==0.19.1\n",
      "jeepney==0.7.1\n",
      "Jinja2==3.1.2\n",
      "jmespath==1.0.1\n",
      "joblib==1.3.2\n",
      "Js2Py==0.74\n",
      "json5==0.9.14\n",
      "jsonlines==4.0.0\n",
      "jsonmerge==1.8.0\n",
      "jsonpatch==1.33\n",
      "jsonpointer==2.4\n",
      "jsonschema==4.19.0\n",
      "jsonschema-specifications==2023.7.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.8.0\n",
      "jupyter-lsp==2.2.0\n",
      "jupyter_client==8.5.0\n",
      "jupyter_core==5.5.0\n",
      "jupyter_server==2.9.1\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==4.0.8\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_server==2.25.0\n",
      "kaggle==1.6.3\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.3.2\n",
      "kornia==0.6.7\n",
      "langchain==0.1.0\n",
      "langchain-community==0.0.10\n",
      "langchain-core==0.1.8\n",
      "langcodes==3.3.0\n",
      "langdetect==1.0.9\n",
      "langsmith==0.0.77\n",
      "language-selector==0.1\n",
      "lark==1.1.2\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lazy_loader==0.3\n",
      "lightning-utilities==0.9.0\n",
      "linkify-it-py==2.0.2\n",
      "lit==16.0.6\n",
      "littleutils==0.2.2\n",
      "llama-cpp-python==0.1.84\n",
      "llvmlite==0.41.0\n",
      "-e git+https://github.com/EleutherAI/lm-evaluation-harness@b69ca72ec3a0294638382e0f90cf32f90d761b44#egg=lm_eval\n",
      "lmdb==1.4.1\n",
      "lockfile==0.12.2\n",
      "loguru==0.6.0\n",
      "looseversion==1.3.0\n",
      "louis==3.20.0\n",
      "lpips==0.1.4\n",
      "lxml==4.8.0\n",
      "lz4==3.1.3+dfsg\n",
      "macaroonbakery==1.3.1\n",
      "Mako==1.1.3\n",
      "mamba-ssm==1.0.1\n",
      "Markdown==3.4.4\n",
      "markdown-it-py==2.2.0\n",
      "MarkupSafe==2.1.3\n",
      "marshmallow==3.20.1\n",
      "matplotlib==3.5.1\n",
      "matplotlib-inline==0.1.6\n",
      "mbstrdecoder==1.1.3\n",
      "mdit-py-plugins==0.3.3\n",
      "mdurl==0.1.2\n",
      "mediapipe==0.10.8\n",
      "mistune==3.0.2\n",
      "monotonic==1.6\n",
      "more-itertools==8.10.0\n",
      "mpmath==0.0.0\n",
      "msgpack==1.0.3\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.15\n",
      "multivolumefile==0.2.3\n",
      "mypy-extensions==1.0.0\n",
      "nbclient==0.8.0\n",
      "nbconvert==7.10.0\n",
      "nbdev==2.3.13\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.5.8\n",
      "netifaces==0.11.0\n",
      "networkx==3.2.1\n",
      "nibabel==5.2.0\n",
      "ninja==1.11.1\n",
      "nipype==1.8.6\n",
      "nltk==3.8.1\n",
      "notebook==7.0.6\n",
      "notebook_shim==0.2.3\n",
      "npm==0.1.1\n",
      "numba==0.58.0\n",
      "numexpr==2.8.7\n",
      "numpy==1.26.3\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.18.1\n",
      "nvidia-nvjitlink-cu12==12.2.140\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "oauthlib==3.2.0\n",
      "objsize==0.6.1\n",
      "ocrmypdf==15.4.0\n",
      "olefile==0.46\n",
      "omegaconf==2.2.3\n",
      "open-clip-torch==2.23.0\n",
      "openai==1.3.6\n",
      "openai-whisper @ git+https://github.com/openai/whisper.git@f6f01c561c45ad6ab421405e18ae22fd0c698e92\n",
      "opencv-contrib-python==4.8.1.78\n",
      "opencv-python==4.8.1.78\n",
      "optimum==1.12.0\n",
      "optional-django==0.1.0\n",
      "ordered-set==4.1.0\n",
      "orjson==3.9.7\n",
      "outcome==1.3.0.post0\n",
      "overrides==7.4.0\n",
      "packages==0.1.1\n",
      "packaging==23.2\n",
      "pandas==2.1.4\n",
      "pandocfilters==1.5.0\n",
      "paramiko==3.4.0\n",
      "parso==0.8.3\n",
      "pathlib==1.0.1\n",
      "pathspec==0.12.1\n",
      "pathtools==0.1.2\n",
      "pathvalidate==3.2.0\n",
      "pdfminer.six==20231228\n",
      "peft==0.8.1\n",
      "pexpect==4.8.0\n",
      "pfzy==0.3.4\n",
      "piexif==1.1.3\n",
      "pikepdf==8.11.2\n",
      "pillow==10.2.0\n",
      "pip-date==1.0.5\n",
      "platformdirs==4.1.0\n",
      "pluggy==1.3.0\n",
      "ply==3.11\n",
      "portalocker==2.8.2\n",
      "prettytable==3.9.0\n",
      "prometheus-client==0.18.0\n",
      "prompt-toolkit==3.0.39\n",
      "proto-plus==1.22.3\n",
      "protobuf==3.20.3\n",
      "prov==2.0.0\n",
      "psutil==5.9.5\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "py7zr==0.20.8\n",
      "pyarrow==11.0.0\n",
      "pyarrow-hotfix==0.6\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.3.0\n",
      "pybcj==1.0.2\n",
      "pybind11==2.11.1\n",
      "pycairo==1.20.1\n",
      "pycares==4.4.0\n",
      "pycountry==22.3.5\n",
      "pycparser==2.21\n",
      "pycryptodomex==3.20.0\n",
      "pycups==2.0.1\n",
      "pydantic==2.5.3\n",
      "pydantic-extra-types==2.5.0\n",
      "pydantic-settings==2.1.0\n",
      "pydantic_core==2.14.6\n",
      "pydeck==0.8.1b0\n",
      "pydot==1.4.2\n",
      "pydub==0.25.1\n",
      "Pygments==2.16.1\n",
      "PyGObject==3.42.1\n",
      "pyjsparser==2.7.1\n",
      "PyJWT==2.3.0\n",
      "pymacaroons==0.13.0\n",
      "pymongo==3.13.0\n",
      "PyMuPDF==1.23.8\n",
      "PyMuPDFb==1.23.7\n",
      "PyNaCl==1.5.0\n",
      "pynvml==11.5.0\n",
      "pyparsing==2.4.7\n",
      "pypdfium2==4.25.0\n",
      "pyppmd==1.1.0\n",
      "pyproject-api==1.6.1\n",
      "pyRFC3339==1.1\n",
      "pysmi==0.3.2\n",
      "pysnmp==4.4.12\n",
      "PySocks==1.7.1\n",
      "pyspellchecker==0.7.3\n",
      "pystache==0.6.0\n",
      "pytablewriter==1.2.0\n",
      "python-apt==2.4.0+ubuntu2\n",
      "python-dateutil==2.8.2\n",
      "python-debian==0.1.43+ubuntu1.1\n",
      "python-dotenv==1.0.0\n",
      "python-json-logger==2.0.7\n",
      "python-magic==0.4.27\n",
      "python-multipart==0.0.6\n",
      "python-rapidjson==1.14\n",
      "python-slugify==8.0.1\n",
      "pythran==0.10.0\n",
      "pytils==0.4.1\n",
      "pytorch-lightning==1.9.4\n",
      "pytube==15.0.0\n",
      "pytz==2022.1\n",
      "PyWavelets==1.4.1\n",
      "pyxdg==0.27\n",
      "pyxnat==1.6\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.1\n",
      "pyzstd==0.15.9\n",
      "qtconsole==5.4.4\n",
      "QtPy==2.4.1\n",
      "rapidfuzz==3.6.1\n",
      "ray==2.9.0\n",
      "rdflib==7.0.0\n",
      "realesrgan==0.3.0\n",
      "redis==3.5.3\n",
      "referencing==0.30.2\n",
      "regex==2023.8.8\n",
      "reportlab==3.6.8\n",
      "requests==2.31.0\n",
      "requests-cache==0.5.2\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==1.0.0\n",
      "resize-right==0.0.2\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.7.0\n",
      "rootpath==0.1.1\n",
      "rouge==1.0.1\n",
      "rouge-score==0.1.2\n",
      "rpds-py==0.10.2\n",
      "rsa==4.9\n",
      "ruff==0.1.15\n",
      "runpod==1.6.0\n",
      "s3transfer==0.10.0\n",
      "sacrebleu==1.5.0\n",
      "safetensors==0.4.2\n",
      "scikit-image==0.21.0\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.12.0\n",
      "screen-resolution-extra==0.0.0\n",
      "seaborn==0.13.1\n",
      "SecretStorage==3.3.1\n",
      "selenium==4.15.2\n",
      "semantic-version==2.10.0\n",
      "Send2Trash==1.8.2\n",
      "sentence-transformers==2.3.1\n",
      "sentencepiece==0.1.99\n",
      "sentry-sdk==1.30.0\n",
      "setproctitle==1.3.2\n",
      "shellingham==1.5.4\n",
      "shortuuid==1.0.11\n",
      "simplejson==3.19.2\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sorcery==0.2.2\n",
      "sortedcontainers==2.4.0\n",
      "sounddevice==0.4.6\n",
      "soupsieve==2.3.1\n",
      "SQLAlchemy==2.0.25\n",
      "sqlitedict==2.1.0\n",
      "ssh-import-id==5.11\n",
      "stack-data==0.6.3\n",
      "starlette==0.35.1\n",
      "streamlit==1.29.0\n",
      "streamlit-drawable-canvas==0.9.3\n",
      "streamlit-drawable-canvas-jsretry==0.9.3\n",
      "streamlit-ext==0.1.9\n",
      "svglib==1.5.1\n",
      "sympy==1.9\n",
      "systemd-python==234\n",
      "tabledata==1.3.3\n",
      "tabulate==0.9.0\n",
      "tb-nightly==2.15.0a20231014\n",
      "tcolorpy==0.1.4\n",
      "tenacity==8.2.3\n",
      "tensorboard==2.14.0\n",
      "tensorboard-data-server==0.7.1\n",
      "termcolor==2.3.0\n",
      "terminado==0.17.1\n",
      "texify==0.1.8\n",
      "text-unidecode==1.3\n",
      "texttable==1.7.0\n",
      "thefuzz==0.20.0\n",
      "threadpoolctl==3.2.0\n",
      "tifffile==2023.9.26\n",
      "tiktoken==0.5.1\n",
      "timm==0.9.12\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.15.1\n",
      "tomesd==0.1.3\n",
      "toml==0.10.2\n",
      "tomli==2.0.1\n",
      "tomlkit==0.12.3\n",
      "tools==0.1.9\n",
      "toolz==0.12.0\n",
      "torch==2.1.0\n",
      "torch-grammar==0.3.3\n",
      "torchaudio==2.1.0\n",
      "torchdiffeq==0.2.3\n",
      "torchmetrics==1.2.0\n",
      "torchsde==0.2.6\n",
      "torchtyping==0.1.4\n",
      "torchvision==0.16.0\n",
      "tornado==6.3.3\n",
      "tox==4.12.1\n",
      "tqdm==4.66.1\n",
      "tqdm-loggable==0.2\n",
      "tqdm-multiprocess==0.0.11\n",
      "traitlets==5.13.0\n",
      "traits==6.3.2\n",
      "trampoline==0.1.2\n",
      "transformers==4.37.2\n",
      "trio==0.23.1\n",
      "trio-websocket==0.11.1\n",
      "triton==2.1.0\n",
      "tritonclient==2.41.1\n",
      "trlx @ git+https://github.com/CarperAI/trlx.git@3340c2f3a56d1d14fdd5f13ad575121fa26b6d92\n",
      "typeguard==4.1.5\n",
      "typepy==1.3.2\n",
      "typer==0.9.0\n",
      "types-python-dateutil==2.8.19.14\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.8.0\n",
      "tzdata==2023.3\n",
      "tzlocal==5.2\n",
      "ubuntu-advantage-tools==8001\n",
      "ubuntu-drivers-common==0.0.0\n",
      "uc-micro-py==1.0.2\n",
      "ufoLib2==0.13.1\n",
      "ufw==0.36.1\n",
      "ujson==5.9.0\n",
      "unattended-upgrades==0.1\n",
      "unicodedata2==14.0.0\n",
      "uri-template==1.3.0\n",
      "urllib3==1.26.16\n",
      "usb-creator==0.3.7\n",
      "uvicorn==0.23.2\n",
      "uvloop==0.19.0\n",
      "validators==0.22.0\n",
      "virtualenv==20.25.0\n",
      "wadllib==1.3.6\n",
      "wandb==0.16.2\n",
      "watchdog==3.0.0\n",
      "watchfiles==0.21.0\n",
      "wcwidth==0.2.12\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.2.3\n",
      "websockets==11.0.3\n",
      "Werkzeug==2.3.7\n",
      "whisper==1.1.10\n",
      "widgetsnbextension==4.0.9\n",
      "wrapt==1.16.0\n",
      "wsproto==1.2.0\n",
      "xdg==5\n",
      "xformers==0.0.22.post4\n",
      "xkit==0.0.0\n",
      "xxhash==3.3.0\n",
      "yacs==0.1.8\n",
      "yapf==0.40.2\n",
      "yarl==1.9.2\n",
      "youtube-dl==2021.12.17\n",
      "zipp==1.0.0\n",
      "zstandard==0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee626605-cfee-4ae7-a98e-8bdfad2f52cb",
   "metadata": {},
   "source": [
    "# 1 Simple example: similarity of single words\n",
    "embedd a few simple words different meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0be147-eda8-4cd1-8e98-2719eb0f7de8",
   "metadata": {},
   "source": [
    "## load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941f3098-8c11-45dc-abcb-62b5672b470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a814cb80-03d1-456e-a147-9fc167891bb3",
   "metadata": {},
   "source": [
    "## embedd samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51c8a09-6ddb-4e81-95b4-b9a132b83bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0398, -0.0315, -0.0107,  ...,  0.0002, -0.0352, -0.0136],\n",
      "        [ 0.0116,  0.0079,  0.0351,  ...,  0.0365, -0.0294,  0.0150],\n",
      "        [-0.0155,  0.0116,  0.0246,  ..., -0.0148, -0.0448, -0.0136],\n",
      "        [ 0.0272,  0.0794,  0.0010,  ...,  0.0121,  0.0031, -0.0031]])\n"
     ]
    }
   ],
   "source": [
    "# code taken from model card of sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"lemon\", \"orange\", \"car\", \"money\"]\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db64f19b-54d7-4dd3-a577-49a6760252d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd4d0e-6b8e-4e12-a725-9464735d7d40",
   "metadata": {},
   "source": [
    "## calculate similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3619240-d782-475f-85b1-46360e62e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemon lemon 1.0\n",
      "lemon orange 0.5340331792831421\n",
      "lemon car 0.29094186425209045\n",
      "lemon money 0.2281380295753479\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sentences)):\n",
    "    print(\n",
    "        sentences[0],\n",
    "        sentences[i],\n",
    "        (sentence_embeddings[0]@sentence_embeddings[i]).item()\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92345dc5-632a-4878-9b8b-6a5545723d79",
   "metadata": {},
   "source": [
    "## PCA and plot in 2d-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd13f2e-1718-4bfb-9c77-70ae05f699ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA, reducing to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "embeddings_2d = pca.fit_transform(sentence_embeddings)\n",
    "\n",
    "# Plotting with labels for each data point\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, point in enumerate(embeddings_2d):\n",
    "    plt.scatter(point[0], point[1], c='blue', edgecolor=None, s=100)\n",
    "    plt.text(point[0] + 0.02, point[1] - 0.014, sentences[i], fontsize=14)\n",
    "\n",
    "plt.title(\"2D PCA Projection of Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.gca().spines['top'].set_visible(False)    # Hide top border\n",
    "plt.gca().spines['right'].set_visible(False)    # Hide top border\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649041b1-91bb-47b9-8306-99226a15b0ea",
   "metadata": {},
   "source": [
    "# 2 Advanced example: embedd questions from public dataset\n",
    "embedd all questions from Open Assistant 2 dataset (g-ronimo/oasst2_top1_en) and find most similar and dissimilar ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430a7f9-82ea-4193-8d1d-7d6bfe8f1a33",
   "metadata": {},
   "source": [
    "## load dataset, extract first question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00066b8-272f-44b4-87d6-33b79fc98a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5419"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"g-ronimo/oasst2_top1_en\")\n",
    "questions = [ d[\"conversation\"][0][\"content\"] for d in dataset[\"train\"]]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53af5e4-886f-4294-9d39-56d4f9074b8e",
   "metadata": {},
   "source": [
    "## embedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfce8690-ddd5-42b3-b72c-1b1fca4fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import torch, gc\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingModelWrapper():\n",
    "    def __init__(self, model_path=\"sentence-transformers/all-mpnet-base-v2\", bs=8):\n",
    "        self.model, self.tokenizer = self.load_model(model_path)\n",
    "        self.bs = bs\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        model = AutoModel.from_pretrained(model_path).cuda()\n",
    "        model.eval()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        return model, tokenizer\n",
    "\n",
    "    def emb_mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def get_embeddings(self, sentences):\n",
    "        embeddings = torch.tensor([],device=\"cuda\")\n",
    "        \n",
    "        if self.bs is None:\n",
    "            batches = [sentences]\n",
    "        else:\n",
    "            batches = [sentences[i:i + self.bs] for i in range(0, len(sentences), self.bs)]  \n",
    "            \n",
    "        for sentences in batches:\n",
    "            encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                model_output = self.model(**encoded_input)        \n",
    "            batch_embeddings=self.emb_mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "            embeddings=torch.cat( (embeddings, batch_embeddings), dim=0 )\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def get_similarities(self, x, y=None):\n",
    "        if y is None:\n",
    "            num_samples=x.shape[0]\n",
    "            similarities = [[0 for i in range(num_samples)] for f in range(num_samples)]\n",
    "            for row in tqdm(range(num_samples)):\n",
    "                similarities[row][0:row+1]=em.cos(x[row].repeat(row+1,1), x[0:row+1]).tolist()\n",
    "            return similarities\n",
    "        else:            \n",
    "            return self.cos(x,y).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9015664f-f8ac-4e9e-abe1-eb27c18fa5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = EmbeddingModelWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3aca829-bc75-4624-ac02-2f59b76969e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentence_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mEmbeddingModelWrapper.get_embeddings\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     32\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(sentences, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 34\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     35\u001b[0m batch_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_mean_pooling(model_output, encoded_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     36\u001b[0m embeddings\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat( (embeddings, batch_embeddings), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:551\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    550\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 551\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    560\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:341\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    339\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 341\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:311\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m    310\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 311\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:280\u001b[0m, in \u001b[0;36mMPNetOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    278\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    279\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 280\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2541\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[0;32m-> 2543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence_embeddings = em.get_embeddings(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac093e7-b42e-4d51-8279-2c398d9a73a2",
   "metadata": {},
   "source": [
    "## plot PCA projection for all question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefc64f-9c72-409b-a6a8-6a98a68fefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA, reducing to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "embeddings_2d = pca.fit_transform(sentence_embeddings)\n",
    "\n",
    "# Plotting with labels for each data point\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, point in enumerate(embeddings_2d):\n",
    "    plt.scatter(point[0], point[1], c='blue', edgecolor='k', s=100)\n",
    "    # plt.text(point[0] + 0.02, point[1] - 0.01, sentences[i], fontsize=12)\n",
    "\n",
    "plt.title(\"2D PCA Projection of Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce4e45-1c7d-42d9-8d84-1cc1fbf2824f",
   "metadata": {},
   "source": [
    "## find most similar and dissimilar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9b00f-e24d-44ed-9b6d-b72ce3f4e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = em.get_similarities(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f7b10-8a79-47a0-ac09-62ea71663b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "minSim, maxSim = 1, -1\n",
    "minSimElement, maxSimElement = [], []\n",
    "\n",
    "for row in range(len(questions)):\n",
    "    for col in range(0, row):\n",
    "        if questions[row].replace(\" \",\"\").lower() == questions[col].replace(\" \", \"\").lower(): continue\n",
    "        sim = similarities[row][col]\n",
    "        if sim > maxSim:\n",
    "            maxSim = sim\n",
    "            maxSimElement = [row, col]\n",
    "        elif sim < minSim:\n",
    "            minSim = sim\n",
    "            minSimElement = [row, col]\n",
    "display([maxSim, maxSimElement])\n",
    "display([minSim, minSimElement])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637d8d7-4a49-4667-a7f2-ea40ff8f705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(questions[maxSimElement[0]], questions[maxSimElement[1]])\n",
    "print()\n",
    "display(questions[minSimElement[0]], questions[minSimElement[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e9cd3-02a1-4fbd-a9e4-d29e5a7065dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA, reducing to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "embeddings_2d = pca.fit_transform(sentence_embeddings.cpu())\n",
    "\n",
    "# Plotting with labels for each data point\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, point in enumerate(embeddings_2d):\n",
    "    col=\"grey\"\n",
    "    alpha=0.1\n",
    "    \n",
    "    if i in maxSimElement:\n",
    "        col=\"green\"\n",
    "        alpha=1\n",
    "    elif i in minSimElement:\n",
    "        col=\"red\"\n",
    "        alpha=1\n",
    "    \n",
    "    plt.scatter(point[0], point[1], c=col, alpha=alpha, edgecolor='black', s=100)\n",
    "    # plt.text(point[0] + 0.02, point[1] - 0.01, sentences[i], fontsize=12)\n",
    "\n",
    "plt.title(\"2D PCA Projection of Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
